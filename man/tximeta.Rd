% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tximeta.R
\name{tximeta}
\alias{tximeta}
\title{tximeta: Transcript quantification import with automatic metadata}
\usage{
tximeta(
  coldata,
  type = "salmon",
  txOut = TRUE,
  skipMeta = FALSE,
  skipSeqinfo = FALSE,
  useHub = TRUE,
  markDuplicateTxps = FALSE,
  cleanDuplicateTxps = FALSE,
  customMetaInfo = NULL,
  ...
)
}
\arguments{
\item{coldata}{a data.frame with at least two columns (others will propogate to object):
\itemize{
\item{\code{files} - character, paths of quantification files}
\item{\code{names} - character, sample names}
}
if \code{coldata} is a vector, it is assumed to be the paths of quantification files
and unique sample names are created}

\item{type}{what quantifier was used (see \code{\link{tximport}})}

\item{txOut}{whether to output transcript-level data.
\code{tximeta} is designed to have transcript-level output
with Salmon, so default is \code{TRUE},
and it's recommended to use \code{\link{summarizeToGene}}
following \code{tximeta} for gene-level summarization.
For an alevin file, \code{tximeta} will import the
gene level counts ignoring this argument (alevin
produces only gene-level quantification).}

\item{skipMeta}{whether to skip metadata generation
(e.g. to avoid errors if not connected to internet).
This calls \code{tximport} directly and so either
\code{txOut=TRUE} or \code{tx2gene} should be specified.}

\item{skipSeqinfo}{whether to skip the addition of Seqinfo,
which requires an internet connection to download the
relevant chromosome information table from UCSC}

\item{useHub}{whether to first attempt to download a TxDb/EnsDb
object from AnnotationHub, rather than creating from a
GTF file from FTP (default is TRUE). If FALSE, it will
force \code{tximeta} to download and parse the GTF}

\item{markDuplicateTxps}{whether to mark the status
(\code{hasDuplicate}) and names of duplicate transcripts
(\code{duplicates}) in the rowData of the SummarizedExperiment output.
Subsequent summarization to gene level will keep track
of the number of transcripts sets per gene (\code{numDupSets})}

\item{cleanDuplicateTxps}{whether to try to clean
duplicate transcripts (exact sequence duplicates) by replacing
the transcript names that do not appear in the GTF
with those that do appear in the GTF}

\item{customMetaInfo}{the relative path to a custom metadata
information JSON file, relative to the paths in \code{files} of
\code{coldata}. For example, \code{customMetaInfo="meta_info.json"}
would indicate that in the same directory as the quantification
files in \code{files}, there are custom metadata information
JSON files. These should contain the SHA-256 hash of the
reference transcripts with the \code{index_seq_hash} tag
(see details in vignette).}

\item{...}{arguments passed to \code{tximport}}
}
\value{
a SummarizedExperiment with metadata on the \code{rowRanges}.
(if the hashed checksum in the Salmon or Sailfish index does not match
any known transcriptomes, or any locally saved \code{linkedTxome},
\code{tximeta} will just return a non-ranged SummarizedExperiment)
}
\description{
\code{tximeta} leverages the hashed checksum of the Salmon index,
in addition to a number of core Bioconductor packages (GenomicFeatures,
ensembldb, AnnotationHub, GenomeInfoDb, BiocFileCache) to automatically
populate metadata for the user, without additional effort from the user.
Note that \code{tximeta} requires that the entire output directory of Salmon
or alevin is present and unmodified in order to identify the provenance of the
reference transcripts.
}
\details{
Most of the code in \code{tximeta} works to add metadata and transcript ranges
when the quantification was performed with Salmon. However,
\code{tximeta} can be used with any quantification \code{type} that is supported
by \code{\link{tximport}}, where it will return an non-ranged SummarizedExperiment.

\code{tximeta} performs a lookup of the hashed checksum of the index
(stored in an auxilary information directory of the Salmon output)
against a database of known transcriptomes, which lives within the tximeta
package and is continually updated on Bioconductor's release schedule.
In addition, \code{tximeta} performs a lookup of the checksum against a
locally stored table of \code{linkedTxome}'s (see \code{link{makeLinkedTxome}}).
If \code{tximeta} detects a match, it will automatically populate,
e.g. the transcript locations, the transcriptome release,
the genome with correct chromosome lengths, etc. It allows for automatic
and correct summarization of transcript-level quantifications to the gene-level
via \code{\link{summarizeToGene}} without the need to manually build
a \code{tx2gene} table.

\code{tximeta} on the first run will ask where the BiocFileCache for
this package should be kept, either using a default location or a temporary
directory. At any point, the user can specify a location using
\code{\link{setTximetaBFC}} and this choice will be saved for future sessions.
Multiple users can point to the same BiocFileCache, such that
transcript databases (TxDb or EnsDb) associated with certain Salmon indices
and \code{linkedTxomes} can be accessed by different users without additional
effort or time spent downloading and building the relevant TxDb / EnsDb.
Note that, if the TxDb or EnsDb is present in AnnotationHub, \code{tximeta} will
use this object instead of downloading and building a TxDb/EnsDb from GTF
(to disable this set useHub=FALSE).

In order to allow that multiple users can read and write to the
same location, one should set the BiocFileCache directory to
have group write permissions (g+w).
}
\examples{

# point to a Salmon quantification file:
dir <- system.file("extdata/salmon_dm", package="tximportData")
files <- file.path(dir, "SRR1197474", "quant.sf") 
coldata <- data.frame(files, names="SRR1197474", condition="A", stringsAsFactors=FALSE)

# normally we would just run the following which would download the appropriate metadata
# se <- tximeta(coldata)

# for this example, we instead point to a local path where the GTF can be found
# by making a linkedTxome:
indexDir <- file.path(dir, "Dm.BDGP6.22.98_salmon-0.14.1")
fastaFTP <- c("ftp://ftp.ensembl.org/pub/release-98/fasta/drosophila_melanogaster/cdna/Drosophila_melanogaster.BDGP6.22.cdna.all.fa.gz",
              "ftp://ftp.ensembl.org/pub/release-98/fasta/drosophila_melanogaster/ncrna/Drosophila_melanogaster.BDGP6.22.ncrna.fa.gz")
gtfPath <- file.path(dir, "Drosophila_melanogaster.BDGP6.22.98.gtf.gz")
makeLinkedTxome(indexDir=indexDir, source="LocalEnsembl", organism="Drosophila melanogaster",
                release="98", genome="BDGP6.22", fasta=fastaFTP, gtf=gtfPath, write=FALSE)
se <- tximeta(coldata)

# to clear the entire linkedTxome table
# (don't run unless you want to clear this table!)
# bfcloc <- getTximetaBFC()
# bfc <- BiocFileCache(bfcloc)
# bfcremove(bfc, bfcquery(bfc, "linkedTxomeTbl")$rid)

}
